{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "126050c0_64b1e826",
        "filename": "trace/flightrecorder.go",
        "patchSetId": 1
      },
      "lineNbr": 115,
      "author": {
        "id": 12120
      },
      "writtenOn": "2023-12-15T22:07:26Z",
      "side": 1,
      "message": "defer r.fromTracer.Close()\n\nEdit: nvm, Close does this. But something needs to close this on trace.Start error.",
      "revId": "989b3afc3b316147e863c7c416716d2f03c855aa",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ea53897e_75abcbca",
        "filename": "trace/flightrecorder.go",
        "patchSetId": 1
      },
      "lineNbr": 199,
      "author": {
        "id": 12120
      },
      "writtenOn": "2023-12-15T22:07:26Z",
      "side": 1,
      "message": "This needs to clean up the goroutine. Closing r.toRecorder might be sufficient?",
      "revId": "989b3afc3b316147e863c7c416716d2f03c855aa",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "509e50f8_04299541",
        "filename": "trace/flightrecorder.go",
        "patchSetId": 1
      },
      "lineNbr": 199,
      "author": {
        "id": 25391
      },
      "writtenOn": "2023-12-21T21:37:15Z",
      "side": 1,
      "message": "ahh good catch. I just reordered this to start the goroutine after instead.",
      "parentUuid": "ea53897e_75abcbca",
      "revId": "989b3afc3b316147e863c7c416716d2f03c855aa",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "7af0f74a_dfa9d56c",
        "filename": "trace/flightrecorder.go",
        "patchSetId": 1
      },
      "lineNbr": 244,
      "author": {
        "id": 12120
      },
      "writtenOn": "2023-12-15T22:07:26Z",
      "side": 1,
      "message": "Can\u0027t use unsynchronized reads to detect concurrent writes, -race will complain.\n\nMy intuition is to just put a lock around this and the loser will have to wait. But perhaps that has too much delay.",
      "revId": "989b3afc3b316147e863c7c416716d2f03c855aa",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f9b4fda8_63c4536e",
        "filename": "trace/flightrecorder.go",
        "patchSetId": 1
      },
      "lineNbr": 244,
      "author": {
        "id": 25391
      },
      "writtenOn": "2023-12-21T21:37:15Z",
      "side": 1,
      "message": "yeah I worry that competing attempts to write will result in misleading traces. I\u0027d rather it fail than not give you back what you wanted.\n\nbut you raise a good point. I made r.writing a mutex, but it\u0027s used as a try-lock. I also made the signal for this condition explicit by adding a sentinel error, so users can deduplicate calls themselves.",
      "parentUuid": "7af0f74a_dfa9d56c",
      "revId": "989b3afc3b316147e863c7c416716d2f03c855aa",
      "serverId": "62eb7196-b449-3ce5-99f1-c037f21e1705"
    }
  ]
}